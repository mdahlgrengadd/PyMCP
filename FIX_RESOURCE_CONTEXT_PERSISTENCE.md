# Fix: Resource Context Persistence Across Turns

## The Problem

**User's excellent observation:** After initial resource injection, follow-up questions lost the context.

### What Was Happening

**Turn 1:**
```
User: "find a tutorial on await"
â†’ Proactive discovery: âœ… Found javascript_async (score: 0.176)
â†’ Injected into context
â†’ LLM provides informed response
```

**Turn 2:**
```
User: "tell me what you know about it"
â†’ Proactive discovery on just "tell me what you know about it"
â†’ âš ï¸ No resources met threshold (score < 0.15)
â†’ No context! âŒ
â†’ LLM uses base knowledge only
```

## Root Cause

### 1. System Message Not in History

```typescript
// main.ts only saves user/assistant messages:
state.conversationHistory.push({ role: 'user', content: message });
state.conversationHistory.push(response); // assistant message

// System message with resources is NOT saved!
```

### 2. Fresh System Message Each Turn

```typescript
// mcp-llm-bridge.ts line 140:
messages[0] = { role: 'system', content: augmentedSystemPrompt };
// â†‘ Creates fresh system message, losing previous resources
```

### 3. Semantic Search Only on Current Query

```typescript
// Old approach:
const initialDiscoveredResources = await this.resourceDiscovery.discoverRelevantResources(
  messages,
  [],
  { topK: 2, minScore: 0.15 }
);
// Only looked at the last user message: "tell me what you know about it"
// Didn't consider Turn 1: "find a tutorial on await"
```

**Result:** Follow-up questions like "tell me more" had no context!

## The Solution: Context-Aware Discovery âœ…

Changed semantic search to consider **full conversation context**, not just the current query:

```typescript
// New approach:
const initialDiscoveredResources = await this.resourceDiscovery.discoverRelevantResources(
  messages,
  [], // No tool results yet, just use conversation
  { topK: 2, minScore: 0.15, lookbackMessages: 5 } // ğŸ†• Look back at recent context!
);
```

### How It Works

The `buildSearchContext` function (in `resource-discovery.ts`) already supports `lookbackMessages`:

```typescript
private buildSearchContext(
  messages: ChatMessage[],
  toolResults: any[],
  lookbackMessages: number
): string {
  const parts: string[] = [];
  
  // Get recent user messages (high weight)
  const recentMessages = messages
    .filter(m => m.role === 'user')
    .slice(-lookbackMessages)  // Last N messages
    .map(m => m.content)
    .join(' ');
  
  if (recentMessages) {
    parts.push(recentMessages);
  }
  
  // Extract text from tool results
  if (toolResults.length > 0) {
    const toolText = extractToolResultText(toolResults);
    if (toolText) {
      parts.push(toolText);
    }
  }
  
  return parts.join(' ');
}
```

## New Flow

### Turn 1 (unchanged):
```
User: "find a tutorial on await"
Messages: [{user: "find a tutorial on await"}]
Search context: "find a tutorial on await"
â†’ âœ… Found javascript_async (score: 0.176)
â†’ Injected into system message
â†’ LLM provides informed response
```

### Turn 2 (fixed!):
```
User: "tell me what you know about it"
Messages: [
  {user: "find a tutorial on await"},
  {assistant: "..."},
  {user: "tell me what you know about it"}
]
Search context: "find a tutorial on await tell me what you know about it" âœ¨
â†’ âœ… Found javascript_async (combined context matches!)
â†’ Injected into system message
â†’ LLM provides informed response with continuous context!
```

## Benefits

### 1. **Natural Conversation Flow** âœ…
Follow-up questions maintain context:
```
User: "teach me about MCP"
â†’ Finds mcp_protocol resource

User: "show me an example"
â†’ Still has mcp_protocol in context (because "MCP" is in history)

User: "what about tools?"
â†’ Still has mcp_protocol in context
```

### 2. **Pronoun Resolution** âœ…
```
User: "find async tutorial"
â†’ Finds javascript_async

User: "tell me more about it"
â†’ "it" = async (from history) â†’ same resource found!
```

### 3. **Progressive Detail** âœ…
```
User: "explain design patterns"
â†’ Finds design_patterns resource

User: "what's the singleton pattern specifically?"
â†’ Still has design_patterns resource (relevant to full conversation)
```

### 4. **Multi-Turn Exploration** âœ…
```
User: "I want to learn about cooking pasta"
â†’ Finds pasta recipes

User: "how do I make it vegan?"
â†’ "it" = pasta (from history) â†’ finds vegan recipes

User: "and gluten free?"
â†’ Combined context finds gluten-free vegan pasta recipes
```

## Configuration

```typescript
{ 
  topK: 2,               // Return top 2 resources
  minScore: 0.15,        // Minimum similarity score
  lookbackMessages: 5    // ğŸ†• Consider last 5 user messages
}
```

**Tuning:**
- **Higher lookbackMessages**: More context, better for long conversations
- **Lower lookbackMessages**: More focused, better for topic changes
- **Default: 5** balances context vs. topic drift

## Comparison: Before vs After

### Before (Context Lost)
```
Turn 1: User asks about "await"
        â†’ Resource injected âœ…
        â†’ Good response âœ…

Turn 2: User asks "tell me more"
        â†’ No resource found âŒ
        â†’ Generic response âŒ
        â†’ User frustrated âŒ
```

### After (Context Persists)
```
Turn 1: User asks about "await"
        â†’ Resource injected âœ…
        â†’ Good response âœ…

Turn 2: User asks "tell me more"
        â†’ Same resource found (history context) âœ…
        â†’ Detailed response âœ…
        â†’ Natural conversation âœ…
```

## Testing

After reloading:

```javascript
// Test 1: Follow-up Question
Turn 1: "find a tutorial on await"
Expected: âœ… Found javascript_async (score > 0.15)

Turn 2: "tell me what you know about it"
Expected: âœ… Found javascript_async (combined context)

// Test 2: Pronoun Reference
Turn 1: "what is MCP?"
Expected: âœ… Found mcp_protocol

Turn 2: "show me an example of it"
Expected: âœ… Found mcp_protocol (MCP still in context)

// Test 3: Topic Change
Turn 1: "async/await tutorial"
Expected: âœ… Found javascript_async

Turn 2: "what about design patterns?"
Expected: âœ… Found design_patterns (new topic, different resource)
```

## Implementation Note

This fix works because:

1. **Conversation history** is passed in from main.ts
2. **buildSearchContext** extracts last N user messages
3. **Combined context** gives better semantic matching
4. **Resources re-discovered** each turn (not cached)
5. **Always fresh** but contextually aware

## Alternative Approaches Considered

### âŒ Approach 1: Save system message in history
```typescript
conversationHistory.push(systemMessage);
```
**Issue:** System message can be very long with resources

### âŒ Approach 2: Cache discovered resources
```typescript
state.activeResources = ['res://javascript_async'];
```
**Issue:** Hard to know when to clear, stale context

### âœ… Approach 3: Context-aware search (implemented)
```typescript
lookbackMessages: 5
```
**Benefit:** Automatic, stateless, always contextually relevant

## Summary

The fix ensures that:

- âœ… Follow-up questions maintain context
- âœ… Pronoun references work ("it", "that", "this")
- âœ… Multi-turn conversations stay coherent
- âœ… Topic changes still work (new resources discovered)
- âœ… No manual state management needed
- âœ… Stateless and scalable

**Reload your app and try:**
```
User: "find a tutorial on await"
User: "tell me more about it"
```

Both turns will now have the `javascript_async` resource in context! ğŸ‰

